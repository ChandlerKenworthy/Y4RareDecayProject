{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapting 5.0.5\n",
    "Currently model 5.0.5 is by far the best performing model. We want to see if we can beat it - in any - or all metrics! We will adapt some of the code used in the Higgs hunting dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Configuration\n",
    "UNITS = 2 ** 6 # 64\n",
    "ACTIVATION = 'relu'\n",
    "DROPOUT = 0.1\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# Training Configuration\n",
    "BATCH_SIZE_PER_REPLICA = 2 ** 10 # powers of 128 are best\n",
    "\n",
    "CSV_HEADER = ['Lb_PT', 'Lb_IPCHI2_OWNPV',' Lb_ENDVERTEX_CHI2', 'Lb_HOP', 'LStar_ORIVX_CHI2', 'LStar_DIRA_OWNPV',\n",
    "              'JPs_FD_ORIVX', 'p_ETA', 'K_ETA', 'L1_ETA', 'L2_ETA', 'Lb_IP01', 'Lb_IP23', 'Lb_IP_OWNPV',\n",
    "              'p_TRACK_VeloCHI2NDOF', 'ABS_ARTANH_PZ_P', 'MAG_ARSINH_PY_PT', 'SUM_CONE_ISO', 'SUM_LIPCHI2', \n",
    "              'LB_TRACKISO', 'LN_COS_THETA', 'LN_LB_MINIPCHI2', 'LN_COS_LBDIRA', 'LN_JPs_DIRA_TOPPV', 'category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_FEATURE_NAME = 'category'\n",
    "\n",
    "\n",
    "FEATURE_NAMES = ['Lb_PT', 'Lb_IPCHI2_OWNPV',' Lb_ENDVERTEX_CHI2', 'Lb_HOP', 'LStar_ORIVX_CHI2', 'LStar_DIRA_OWNPV',\n",
    "              'JPs_FD_ORIVX', 'p_ETA', 'K_ETA', 'L1_ETA', 'L2_ETA', 'Lb_IP01', 'Lb_IP23', 'Lb_IP_OWNPV',\n",
    "              'p_TRACK_VeloCHI2NDOF', 'ABS_ARTANH_PZ_P', 'MAG_ARSINH_PY_PT', 'SUM_CONE_ISO', 'SUM_LIPCHI2', \n",
    "              'LB_TRACKISO', 'LN_COS_THETA', 'LN_LB_MINIPCHI2', 'LN_COS_LBDIRA', 'LN_JPs_DIRA_TOPPV']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_from_csv(csv_file_path, batch_size, shuffle=False):\n",
    "\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        csv_file_path,\n",
    "        batch_size=batch_size,\n",
    "        column_names=CSV_HEADER,\n",
    "        column_defaults=[tf.float32 for i in CSV_HEADER],\n",
    "        label_name=TARGET_FEATURE_NAME,\n",
    "        num_epochs=1,\n",
    "        header=True,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return dataset.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "dropout_rate = 0.1\n",
    "batch_size = 265\n",
    "num_epochs = 50\n",
    "\n",
    "hidden_units = [32, 32]\n",
    "\n",
    "\n",
    "def run_experiment(model):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[keras.metrics.BinaryAccuracy()],\n",
    "    )\n",
    "\n",
    "    train_dataset = get_dataset_from_csv('data_5.0.5/train_data.csv', batch_size, shuffle=True)\n",
    "\n",
    "    test_dataset = get_dataset_from_csv('data_5.0.5/test_data.csv', batch_size)\n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    history = model.fit(train_dataset, epochs=num_epochs)\n",
    "    print(\"Model training finished\")\n",
    "\n",
    "    _, accuracy = model.evaluate(test_dataset, verbose=0)\n",
    "\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        inputs[feature_name] = layers.Input(\n",
    "            name=feature_name, shape=(), dtype=tf.float32\n",
    "        )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_inputs(inputs):\n",
    "    encoded_features = []\n",
    "    for feature_name in inputs:\n",
    "        encoded_feature = tf.expand_dims(inputs[feature_name], -1)\n",
    "        encoded_features.append(encoded_feature)\n",
    "    all_features = layers.concatenate(encoded_features)\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 10:29:14.720479: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-25 10:29:14.725274: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "def create_baseline_model():\n",
    "    inputs = create_model_inputs()\n",
    "    features = encode_inputs(inputs)\n",
    "\n",
    "    for units in hidden_units:\n",
    "        features = layers.Dense(units)(features)\n",
    "        features = layers.BatchNormalization()(features)\n",
    "        features = layers.ReLU()(features)\n",
    "        features = layers.Dropout(dropout_rate)(features)\n",
    "\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "baseline_model = create_baseline_model()\n",
    "keras.utils.plot_model(baseline_model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 10:29:15.262513: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-02-25 10:29:15.275686: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2400145000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 3s 13ms/step - loss: 0.4707 - binary_accuracy: 0.7837\n",
      "Epoch 2/50\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.2616 - binary_accuracy: 0.8983\n",
      "Epoch 3/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2312 - binary_accuracy: 0.9079\n",
      "Epoch 4/50\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.2162 - binary_accuracy: 0.9141\n",
      "Epoch 5/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2061 - binary_accuracy: 0.9187\n",
      "Epoch 6/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2009 - binary_accuracy: 0.9212\n",
      "Epoch 7/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1960 - binary_accuracy: 0.9212\n",
      "Epoch 8/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1920 - binary_accuracy: 0.9231\n",
      "Epoch 9/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1896 - binary_accuracy: 0.9248\n",
      "Epoch 10/50\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1879 - binary_accuracy: 0.9258\n",
      "Epoch 11/50\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1829 - binary_accuracy: 0.9276\n",
      "Epoch 12/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1830 - binary_accuracy: 0.9281\n",
      "Epoch 13/50\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1811 - binary_accuracy: 0.9279\n",
      "Epoch 14/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1771 - binary_accuracy: 0.9310\n",
      "Epoch 15/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1795 - binary_accuracy: 0.9294\n",
      "Epoch 16/50\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1757 - binary_accuracy: 0.9306\n",
      "Epoch 17/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1749 - binary_accuracy: 0.9299\n",
      "Epoch 18/50\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.1737 - binary_accuracy: 0.9314\n",
      "Epoch 19/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1744 - binary_accuracy: 0.9313\n",
      "Epoch 20/50\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1701 - binary_accuracy: 0.9337\n",
      "Epoch 21/50\n",
      "83/83 [==============================] - 2s 19ms/step - loss: 0.1710 - binary_accuracy: 0.9325\n",
      "Epoch 22/50\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 0.1726 - binary_accuracy: 0.9304\n",
      "Epoch 23/50\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1705 - binary_accuracy: 0.9321\n",
      "Epoch 24/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1698 - binary_accuracy: 0.9324\n",
      "Epoch 25/50\n",
      "83/83 [==============================] - 1s 15ms/step - loss: 0.1684 - binary_accuracy: 0.9328\n",
      "Epoch 26/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1677 - binary_accuracy: 0.9334\n",
      "Epoch 27/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1671 - binary_accuracy: 0.9348\n",
      "Epoch 28/50\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1659 - binary_accuracy: 0.9341\n",
      "Epoch 29/50\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1673 - binary_accuracy: 0.9328\n",
      "Epoch 30/50\n",
      "83/83 [==============================] - 1s 15ms/step - loss: 0.1672 - binary_accuracy: 0.9331\n",
      "Epoch 31/50\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.1645 - binary_accuracy: 0.9344\n",
      "Epoch 32/50\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1644 - binary_accuracy: 0.9338\n",
      "Epoch 33/50\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1654 - binary_accuracy: 0.9345\n",
      "Epoch 34/50\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1640 - binary_accuracy: 0.9347\n",
      "Epoch 35/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1639 - binary_accuracy: 0.9352\n",
      "Epoch 36/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1628 - binary_accuracy: 0.9353\n",
      "Epoch 37/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1629 - binary_accuracy: 0.9350\n",
      "Epoch 38/50\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1624 - binary_accuracy: 0.9336\n",
      "Epoch 39/50\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1624 - binary_accuracy: 0.9343\n",
      "Epoch 40/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1616 - binary_accuracy: 0.9361\n",
      "Epoch 41/50\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1612 - binary_accuracy: 0.9347\n",
      "Epoch 42/50\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1624 - binary_accuracy: 0.9361\n",
      "Epoch 43/50\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1617 - binary_accuracy: 0.9348\n",
      "Epoch 44/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1600 - binary_accuracy: 0.9365\n",
      "Epoch 45/50\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1602 - binary_accuracy: 0.9366\n",
      "Epoch 46/50\n",
      "83/83 [==============================] - 1s 15ms/step - loss: 0.1593 - binary_accuracy: 0.9364\n",
      "Epoch 47/50\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1584 - binary_accuracy: 0.9379\n",
      "Epoch 48/50\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.1592 - binary_accuracy: 0.9360\n",
      "Epoch 49/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1600 - binary_accuracy: 0.9361\n",
      "Epoch 50/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1575 - binary_accuracy: 0.9373\n",
      "Model training finished\n",
      "Test accuracy: 93.76%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x7eff3022a190>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_experiment(baseline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "def create_wide_and_deep_model():\n",
    "\n",
    "    inputs = create_model_inputs()\n",
    "    wide = encode_inputs(inputs)\n",
    "    wide = layers.BatchNormalization()(wide)\n",
    "\n",
    "    deep = encode_inputs(inputs)\n",
    "    for units in hidden_units:\n",
    "        deep = layers.Dense(units)(deep)\n",
    "        deep = layers.BatchNormalization()(deep)\n",
    "        deep = layers.ReLU()(deep)\n",
    "        deep = layers.Dropout(dropout_rate)(deep)\n",
    "\n",
    "    merged = layers.concatenate([wide, deep])\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(merged)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "wide_and_deep_model = create_wide_and_deep_model()\n",
    "keras.utils.plot_model(wide_and_deep_model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/50\n",
      "83/83 [==============================] - 3s 17ms/step - loss: 0.4498 - binary_accuracy: 0.7885\n",
      "Epoch 2/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2523 - binary_accuracy: 0.9033\n",
      "Epoch 3/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2211 - binary_accuracy: 0.9120\n",
      "Epoch 4/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2093 - binary_accuracy: 0.9172\n",
      "Epoch 5/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2011 - binary_accuracy: 0.9202\n",
      "Epoch 6/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1967 - binary_accuracy: 0.9215\n",
      "Epoch 7/50\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1919 - binary_accuracy: 0.9240\n",
      "Epoch 8/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1893 - binary_accuracy: 0.9254\n",
      "Epoch 9/50\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1867 - binary_accuracy: 0.9261\n",
      "Epoch 10/50\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1848 - binary_accuracy: 0.9269\n",
      "Epoch 11/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1833 - binary_accuracy: 0.9286\n",
      "Epoch 12/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1816 - binary_accuracy: 0.9274\n",
      "Epoch 13/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1791 - binary_accuracy: 0.9293\n",
      "Epoch 14/50\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1769 - binary_accuracy: 0.9289\n",
      "Epoch 15/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1762 - binary_accuracy: 0.9292\n",
      "Epoch 16/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1748 - binary_accuracy: 0.9305\n",
      "Epoch 17/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1740 - binary_accuracy: 0.9313\n",
      "Epoch 18/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1724 - binary_accuracy: 0.9317\n",
      "Epoch 19/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1731 - binary_accuracy: 0.9306\n",
      "Epoch 20/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1718 - binary_accuracy: 0.9315\n",
      "Epoch 21/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1696 - binary_accuracy: 0.9329\n",
      "Epoch 22/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1689 - binary_accuracy: 0.9333\n",
      "Epoch 23/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1678 - binary_accuracy: 0.9329\n",
      "Epoch 24/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1674 - binary_accuracy: 0.9355\n",
      "Epoch 25/50\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1654 - binary_accuracy: 0.9354\n",
      "Epoch 26/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1670 - binary_accuracy: 0.9331\n",
      "Epoch 27/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1658 - binary_accuracy: 0.9341\n",
      "Epoch 28/50\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1657 - binary_accuracy: 0.9342\n",
      "Epoch 29/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1647 - binary_accuracy: 0.9344\n",
      "Epoch 30/50\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1642 - binary_accuracy: 0.9341\n",
      "Epoch 31/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1629 - binary_accuracy: 0.9354\n",
      "Epoch 32/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1633 - binary_accuracy: 0.9360\n",
      "Epoch 33/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1631 - binary_accuracy: 0.9363\n",
      "Epoch 34/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1605 - binary_accuracy: 0.9359\n",
      "Epoch 35/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1617 - binary_accuracy: 0.9358\n",
      "Epoch 36/50\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1614 - binary_accuracy: 0.9367\n",
      "Epoch 37/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1604 - binary_accuracy: 0.9372\n",
      "Epoch 38/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1605 - binary_accuracy: 0.9370\n",
      "Epoch 39/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1575 - binary_accuracy: 0.9378\n",
      "Epoch 40/50\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1572 - binary_accuracy: 0.9381\n",
      "Epoch 41/50\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1570 - binary_accuracy: 0.9375\n",
      "Epoch 42/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1589 - binary_accuracy: 0.9388\n",
      "Epoch 43/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1558 - binary_accuracy: 0.9386\n",
      "Epoch 44/50\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.1562 - binary_accuracy: 0.9393\n",
      "Epoch 45/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1560 - binary_accuracy: 0.9389\n",
      "Epoch 46/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1578 - binary_accuracy: 0.9378\n",
      "Epoch 47/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1552 - binary_accuracy: 0.9377\n",
      "Epoch 48/50\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1547 - binary_accuracy: 0.9400\n",
      "Epoch 49/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1538 - binary_accuracy: 0.9387\n",
      "Epoch 50/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1549 - binary_accuracy: 0.9396\n",
      "Model training finished\n",
      "Test accuracy: 93.72%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x7efef8565ca0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_experiment(wide_and_deep_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "def create_deep_and_cross_model():\n",
    "\n",
    "    inputs = create_model_inputs()\n",
    "    x0 = encode_inputs(inputs)\n",
    "\n",
    "    cross = x0\n",
    "    for _ in hidden_units:\n",
    "        units = cross.shape[-1]\n",
    "        x = layers.Dense(units)(cross)\n",
    "        cross = x0 * x + cross\n",
    "    cross = layers.BatchNormalization()(cross)\n",
    "\n",
    "    deep = x0\n",
    "    for units in hidden_units:\n",
    "        deep = layers.Dense(units)(deep)\n",
    "        deep = layers.BatchNormalization()(deep)\n",
    "        deep = layers.ReLU()(deep)\n",
    "        deep = layers.Dropout(dropout_rate)(deep)\n",
    "\n",
    "    merged = layers.concatenate([cross, deep])\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(merged)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "deep_and_cross_model = create_deep_and_cross_model()\n",
    "keras.utils.plot_model(deep_and_cross_model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/50\n",
      "83/83 [==============================] - 3s 18ms/step - loss: 0.4091 - binary_accuracy: 0.8260\n",
      "Epoch 2/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2454 - binary_accuracy: 0.9063\n",
      "Epoch 3/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2117 - binary_accuracy: 0.9173\n",
      "Epoch 4/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1996 - binary_accuracy: 0.9219\n",
      "Epoch 5/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1923 - binary_accuracy: 0.9244\n",
      "Epoch 6/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1863 - binary_accuracy: 0.9262\n",
      "Epoch 7/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1835 - binary_accuracy: 0.9261\n",
      "Epoch 8/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1799 - binary_accuracy: 0.9279\n",
      "Epoch 9/50\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1775 - binary_accuracy: 0.9294\n",
      "Epoch 10/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1763 - binary_accuracy: 0.9295\n",
      "Epoch 11/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1753 - binary_accuracy: 0.9300\n",
      "Epoch 12/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1719 - binary_accuracy: 0.9326\n",
      "Epoch 13/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1701 - binary_accuracy: 0.9329\n",
      "Epoch 14/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1682 - binary_accuracy: 0.9348\n",
      "Epoch 15/50\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1657 - binary_accuracy: 0.9341\n",
      "Epoch 16/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1665 - binary_accuracy: 0.9342\n",
      "Epoch 17/50\n",
      "83/83 [==============================] - 1s 17ms/step - loss: 0.1642 - binary_accuracy: 0.9348\n",
      "Epoch 18/50\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1625 - binary_accuracy: 0.9359\n",
      "Epoch 19/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1619 - binary_accuracy: 0.9362\n",
      "Epoch 20/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1598 - binary_accuracy: 0.9366\n",
      "Epoch 21/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1582 - binary_accuracy: 0.9375\n",
      "Epoch 22/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1590 - binary_accuracy: 0.9367\n",
      "Epoch 23/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1555 - binary_accuracy: 0.9383\n",
      "Epoch 24/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1550 - binary_accuracy: 0.9393\n",
      "Epoch 25/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1540 - binary_accuracy: 0.9393\n",
      "Epoch 26/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1537 - binary_accuracy: 0.9384\n",
      "Epoch 27/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1526 - binary_accuracy: 0.9388\n",
      "Epoch 28/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1530 - binary_accuracy: 0.9396\n",
      "Epoch 29/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1528 - binary_accuracy: 0.9390\n",
      "Epoch 30/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1505 - binary_accuracy: 0.9412\n",
      "Epoch 31/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1496 - binary_accuracy: 0.9410\n",
      "Epoch 32/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1486 - binary_accuracy: 0.9420\n",
      "Epoch 33/50\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1472 - binary_accuracy: 0.9412\n",
      "Epoch 34/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1483 - binary_accuracy: 0.9419\n",
      "Epoch 35/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1468 - binary_accuracy: 0.9413\n",
      "Epoch 36/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1460 - binary_accuracy: 0.9427\n",
      "Epoch 37/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1461 - binary_accuracy: 0.9430\n",
      "Epoch 38/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1434 - binary_accuracy: 0.9441\n",
      "Epoch 39/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1436 - binary_accuracy: 0.9431\n",
      "Epoch 40/50\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.1425 - binary_accuracy: 0.9443\n",
      "Epoch 41/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1419 - binary_accuracy: 0.9438\n",
      "Epoch 42/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1425 - binary_accuracy: 0.9446\n",
      "Epoch 43/50\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1417 - binary_accuracy: 0.9441\n",
      "Epoch 44/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1402 - binary_accuracy: 0.9447\n",
      "Epoch 45/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1395 - binary_accuracy: 0.9457\n",
      "Epoch 46/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1395 - binary_accuracy: 0.9452\n",
      "Epoch 47/50\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.1390 - binary_accuracy: 0.9442\n",
      "Epoch 48/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1376 - binary_accuracy: 0.9451\n",
      "Epoch 49/50\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.1378 - binary_accuracy: 0.9452\n",
      "Epoch 50/50\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.1370 - binary_accuracy: 0.9469\n",
      "Model training finished\n",
      "Test accuracy: 93.63%\n"
     ]
    }
   ],
   "source": [
    "deep_cross_model = run_experiment(deep_and_cross_model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ca4116ab2c7470d45496f3104a2f3648c94db730a0039ceabb3a0fb6fe42410"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('linux-64')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
