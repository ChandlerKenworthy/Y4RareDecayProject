{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c1b0d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76663d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import Data, Consts\n",
    "import data_pipeline as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfdfdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "real = Data(*Consts().get_real_tuple())\n",
    "siml = Data(*Consts().get_simulated_tuple())\n",
    "\n",
    "particle_features = ['Theta', 'MINIP', 'PX', 'PY', 'PZ', 'PT', 'ProbNNe', 'ProbNNk', 'ProbNNpi', 'ProbNNp', 'ProbNNmu', 'ProbNNd', 'ProbNNghost']\n",
    "particles = ['L1', 'L2', 'p', 'K']\n",
    "request_features = [particle + \"_\" + feature for feature in particle_features for particle in particles] + ['Lb_DTF_PV_chi2']\n",
    "\n",
    "rf, sf = real.fetch_features(request_features), siml.fetch_features(request_features + ['Lb_BKGCAT'])\n",
    "\n",
    "rf['category'] = 0\n",
    "sf['category'] = np.where(sf['Lb_BKGCAT'].isin([10, 50]), 1, 2)\n",
    "# Add the category tags before combining these data, \n",
    "\n",
    "# 0 = Real background \n",
    "# 1 = Simulated Signal\n",
    "# 2 = Simulated Background\n",
    "\n",
    "sf.drop('Lb_BKGCAT', inplace=True, axis=1)\n",
    "sf.reset_index(inplace=True)\n",
    "rf.reset_index(inplace=True)\n",
    "\n",
    "probnn_features = [particle + \"_\" + ft for ft in ['ProbNNe', 'ProbNNk', 'ProbNNpi', 'ProbNNp', 'ProbNNmu', 'ProbNNd', 'ProbNNghost'] for particle in particles]\n",
    "sf[probnn_features] = sf[probnn_features].mask(sf[probnn_features] < 0, 0)\n",
    "rf[probnn_features] = rf[probnn_features].mask(rf[probnn_features] < 0, 0)\n",
    "\n",
    "df = pd.concat([rf, sf], ignore_index=True, sort=False)\n",
    "df.drop('eventNumber', inplace=True, axis=1)\n",
    "\n",
    "for particle in particles:\n",
    "    df[particle + \"_P\"] = np.sqrt(df[particle + \"_PT\"]**2 + df[particle + \"_PZ\"]**2)\n",
    "    df[particle + '_alpha'] = np.arcsin(df[particle + '_PT']/df[particle + '_P'])\n",
    "# Alpha is the angle between the particle and the beam axis, not using Theta as this has\n",
    "# already been used to describe another feature\n",
    "\n",
    "# Now let us make features describing the absolute differences in normalised transverse\n",
    "# momentum values between all combinations of the final state particles\n",
    "for particle in particles:\n",
    "    df[particle + '_normPT'] = df[particle + \"_PT\"]/df[particle + \"_P\"]\n",
    "    # Make the normalised PT values for each particle easily accessible\n",
    "    \n",
    "combinations = np.array([\n",
    "    ['L1', 'L2'],\n",
    "    ['L1', 'p'],\n",
    "    ['L1', 'K'],\n",
    "    ['L2', 'p'],\n",
    "    ['L2', 'K'],\n",
    "    ['p', 'K']\n",
    "])\n",
    "\n",
    "for combo in combinations:\n",
    "    name = f\"{combo[0]}_minus_{combo[1]}\"\n",
    "    df[name] = df[combo[0] + \"_normPT\"] - df[combo[1] + \"_normPT\"]\n",
    "\n",
    "xf = df.drop(probnn_features, axis=1)\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = dp.prepare_data(xf, train_frac=0.6, val_frac=0.2, test_frac=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6a23589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 14:46:46.721341: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-04 14:46:46.737562: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'xf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2670414/675203449.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml1_l2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xf' is not defined"
     ]
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(patience=30, min_delta=0.0005, restore_best_weights=True)\n",
    "\n",
    "m = keras.Sequential()\n",
    "m.add(layers.Dense(64, activation='relu', input_shape=(len(df.columns)-1,), kernel_regularizer=l1_l2(0.001, 0.001)))\n",
    "m.add(layers.Dropout(0.2))\n",
    "m.add(layers.BatchNormalization())\n",
    "m.add(layers.Dense(128, activation='relu', kernel_regularizer=l1_l2(0.001, 0.001)))\n",
    "m.add(layers.Dropout(0.2))\n",
    "m.add(layers.Dense(128, activation='relu', kernel_regularizer=l1_l2(0.001, 0.001)))\n",
    "m.add(layers.BatchNormalization())\n",
    "m.add(layers.Dense(256, activation='relu', kernel_regularizer=l1_l2(0.001, 0.001)))\n",
    "m.add(layers.Dense(1, activation='sigmoid'))\n",
    "m.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics='binary_accuracy')\n",
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c865faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_history = m.fit(X_train, y_train, epochs=500, batch_size=1024, validation_data=(X_val, y_val), callbacks=[early_stopping])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lb-dog",
   "language": "python",
   "name": "lb-dog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
