{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Cuts\n",
    "This notebook explores some manual cuts we can make on the data based on analysis, performed below, on features distinguishing signal from background. We use some educated guessing as to what variables might be distinguishing but also some physically motivated cuts which will be explained as and when they are performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Constants\n",
    "Firstly we quickly import all the modules we are going to need during this analysis. The utilities module contains all our classes that can be used for data manupulation and calling in constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utilities import Data, Consts, Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFNAME, RSUFFIX = Consts().get_real_tuple()\n",
    "SFNAME, SSUFFIX = Consts().get_simulated_tuple()\n",
    "PARTICLES = [\"p\", \"K\", \"L1\", \"L2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data & Cut Objects\n",
    "Now we have the file paths and decay trees we wish to analyse, that is those of the real blinded LHCb data and Monte-Carlo simulated signal, we can construct some Data objects which will keep track of these data as cuts are performed. We also create a Cut object which will be used to calculate the cut paramters for some given cuts and then apply them to multiple Data objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "real, sim = Data(RFNAME, RSUFFIX), Data(SFNAME, SSUFFIX)\n",
    "rcut = Cut(real)\n",
    "scut = Cut(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Different Cuts\n",
    "Now we apply some different cuts and evaluate their behaviour between the signal and background data sets. Note the real data contains only background data as the blinded region is removed. The simulated data contains the Monte-Carlo simulated signal peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fts = ['MINIP']\n",
    "features = [particle + \"_\" + ft for ft in fts for particle in PARTICLES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin the Run Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = sim.fetch_features([\"Lb_BKGCAT\"] + features)\n",
    "rdf = real.fetch_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_MINIP</th>\n",
       "      <th>K_MINIP</th>\n",
       "      <th>L1_MINIP</th>\n",
       "      <th>L2_MINIP</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4826</th>\n",
       "      <td>0.250324</td>\n",
       "      <td>0.298112</td>\n",
       "      <td>0.356679</td>\n",
       "      <td>0.202964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4839</th>\n",
       "      <td>0.369802</td>\n",
       "      <td>0.605301</td>\n",
       "      <td>0.244739</td>\n",
       "      <td>0.361498</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>0.101261</td>\n",
       "      <td>0.167225</td>\n",
       "      <td>0.116537</td>\n",
       "      <td>0.351074</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>0.179403</td>\n",
       "      <td>0.478647</td>\n",
       "      <td>0.253145</td>\n",
       "      <td>0.285299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>0.560972</td>\n",
       "      <td>0.381322</td>\n",
       "      <td>0.556597</td>\n",
       "      <td>0.313683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              p_MINIP   K_MINIP  L1_MINIP  L2_MINIP  Category\n",
       "eventNumber                                                  \n",
       "4826         0.250324  0.298112  0.356679  0.202964         0\n",
       "4839         0.369802  0.605301  0.244739  0.361498         1\n",
       "4844         0.101261  0.167225  0.116537  0.351074         1\n",
       "1686         0.179403  0.478647  0.253145  0.285299         0\n",
       "1603         0.560972  0.381322  0.556597  0.313683         0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf['Category'] = np.where(sdf['Lb_BKGCAT'].isin([10, 50]), 1, 0) # 1 is a signal event and 0 is a background event\n",
    "sdf.drop('Lb_BKGCAT', axis=1, inplace=True)\n",
    "sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for particle in PARTICLES:\n",
    "    sdf[particle + \"_PT\"] = np.sqrt(sdf[particle + \"_PX\"]**2 + sdf[particle + \"_PY\"]**2)\n",
    "    sdf[particle + \"_P\"] = np.sqrt(sdf[particle + \"_PT\"]**2 + sdf[particle + \"_PZ\"]**2)\n",
    "    sdf[particle + \"_ThetaCalc\"] = np.arcsin(sdf[particle + \"_PT\"]/sdf[particle + \"_P\"])\n",
    "    sdf[particle + \"_ETACalc\"] = -np.log(np.tan(sdf[particle + \"_ThetaCalc\"]/2))\n",
    "    sdf.drop([particle + \"_PX\", particle + \"_PY\", particle + \"_PZ\"], axis=1, inplace=True)\n",
    "    \n",
    "    rdf[particle + \"_PT\"] = np.sqrt(rdf[particle + \"_PX\"]**2 + rdf[particle + \"_PY\"]**2)\n",
    "    rdf[particle + \"_P\"] = np.sqrt(rdf[particle + \"_PT\"]**2 + rdf[particle + \"_PZ\"]**2)\n",
    "    rdf[particle + \"_ThetaCalc\"] = np.arcsin(rdf[particle + \"_PT\"]/rdf[particle + \"_P\"])\n",
    "    rdf[particle + \"_ETACalc\"] = -np.log(np.tan(rdf[particle + \"_ThetaCalc\"]/2))\n",
    "    rdf.drop([particle + \"_PX\", particle + \"_PY\", particle + \"_PZ\"], axis=1, inplace=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sdf.groupby('Category')\n",
    "#features = ['Theta', 'ThetaCalc', 'ETA', 'ETACalc']\n",
    "#features = [particle + \"_\" + feature for feature in features for particle in PARTICLES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting p_MINIP\n",
      "Starting K_MINIP\n",
      "Starting L1_MINIP\n",
      "Starting L2_MINIP\n"
     ]
    }
   ],
   "source": [
    "fancy_names = {'L1': \"$\\mu$\", 'L2': \"e\", 'p': \"p\", 'K': 'K'}\n",
    "\n",
    "nbins = 100\n",
    "for variable in features:\n",
    "    print(f'Starting {variable}')\n",
    "    feature = variable.split('_')\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(9, 7))\n",
    "    hist = ax.hist(g.get_group(1)[variable], label='MC Signal', bins=nbins, histtype='bar', edgecolor='k', alpha=0.6, density=True)\n",
    "    ax.hist(g.get_group(0)[variable], label='MC Background', bins=hist[1], histtype='bar', edgecolor='k', alpha=0.6, density=True)\n",
    "    ax.hist(rdf[variable], label='Real Background', bins=hist[1], histtype='bar', edgecolor='k', alpha=0.6, density=True)\n",
    "    ax.set_ylabel('Normalised Frequency')\n",
    "    ax.set_xlabel(rf'{feature[1]} of {fancy_names[feature[0]]}')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'/home/user211/project/images/Eta/{variable}.png') # Save the figure\n",
    "    plt.close() # Prevent plot rendering to save compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Cut Paramters\n",
    "So we have identified a cut we might care about that is cutting positively and negatively around p_ProbNNp and p_ProbNNk respectively. We need to tune the paramters to optimise these cuts and we do this by plotting some FoM against the paramter being tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sb_foms(grouped_data):\n",
    "    s = np.array([len(g.get_group(1)) for g in grouped_data])\n",
    "    b = np.array([len(g.get_group(0)) for g in grouped_data])\n",
    "    return s/np.sqrt(b), s/np.sqrt(s+b)\n",
    "\n",
    "def punzi_fom(original_data, grouped_cut_data, a=5):\n",
    "    # By default use a 5 sigma CL\n",
    "    slens = np.array([len(g.get_group(1)) for g in grouped_cut_data]) # Amount of signal events in data after cuts applied\n",
    "    blens = np.array([len(g.get_group(0)) for g in grouped_cut_data]) # Amount of background events in data after cuts applied\n",
    "    return (slens/len(original_data.groupby('Category').get_group(1)))/((a/2) + np.sqrt(blens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lower' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2076276/826955880.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobnnp_cut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lower' is not defined"
     ]
    }
   ],
   "source": [
    "def probnnp_cut(data, p):\n",
    "    d = []\n",
    "    for prob in p:\n",
    "        x = data.loc[data[fut] <= prob]\n",
    "        d.append(x.groupby('Category'))\n",
    "    return d\n",
    "\n",
    "ptr = np.linspace(0.2, 0.8, 500)\n",
    "dab = probnnp_cut(sdf, ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_line = ptr[np.argmax(punzi_fom(sdf, dab))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(9, 7))\n",
    "\n",
    "ax.scatter(ptr, punzi_fom(sdf, dab), label='Punzi FoM', s=2)\n",
    "print(max_line)\n",
    "ax.set_ylabel('Punzi Figure of Merit Value (arb)')\n",
    "ax.set_xlabel('Probability value to cut data below')\n",
    "plt.axvline(max_line, c='r', label=f'p={max_line:.4f}')\n",
    "plt.title(f'Punzi FoM versus value of {fut} cut parameter')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(f'/home/user211/project/images/punzi_{fut}.png')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ca4116ab2c7470d45496f3104a2f3648c94db730a0039ceabb3a0fb6fe42410"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('linux-64': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
