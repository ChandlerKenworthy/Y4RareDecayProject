{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Evaluation\n",
    "We will now evaluate how each model evaluates features by randomly shuffling a single column in turn and seeing how this impacts the binary accuracy score. Features of greater importance should effect this score to a larger degree. Thus feature importance is proportional to the magnitude of the change in the performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from joblib import load\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "plt.style.use([hep.style.ROOT, hep.style.firamath])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '9.0.5'\n",
    "train = pd.read_csv(f'../data_files/{version}/train.csv', index_col=[0])\n",
    "X_train = train.drop(['category', 'Lb_M', 'IsSimulated'], axis=1)\n",
    "y_train = train.category\n",
    "\n",
    "val = df = pd.read_csv(f'../data_files/{version}/val.csv', index_col=[0])\n",
    "X_val = val.drop(['category', 'Lb_M', 'IsSimulated'], axis=1)\n",
    "y_val = val.category\n",
    "\n",
    "test = df = pd.read_csv(f'../data_files/{version}/test.csv', index_col=[0])\n",
    "X_test = test.drop(['category', 'Lb_M', 'IsSimulated'], axis=1)\n",
    "y_test = test.category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/envs/scientific/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator KNeighborsClassifier from version 0.24.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/root/envs/scientific/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.24.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/root/envs/scientific/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.24.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nn = tf.keras.models.load_model(f'../neural_network/models/v{version}')\n",
    "old_nn = tf.keras.models.load_model(f'../neural_network/models/v{version}')\n",
    "knn = load(f'../classification_methods/models/KNN_{version}_tune.joblib')\n",
    "rfc = load(f'../classification_methods/models/RFC_{version}_tune.joblib')\n",
    "dtc = load(f'../classification_methods/models/DTC_{version}_tune.joblib')\n",
    "xgb = load(f'../classification_methods/models/XGB_{version}.joblib')\n",
    "\n",
    "models = {'NN': nn, 'KNN': knn, 'RFC': rfc, 'DTC': dtc, 'OLDNN': old_nn, 'XGB': xgb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_shuffle = X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95140\n",
      "Accuracy: 0.94146\n",
      "Accuracy: 0.95360\n",
      "Accuracy: 0.92442\n",
      "Accuracy: 0.95140\n",
      "Accuracy: 0.96276\n"
     ]
    }
   ],
   "source": [
    "orig_accs = []\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        preds = model.predict_proba(X_train.to_numpy())[:,1]\n",
    "    except:\n",
    "        preds = model.predict(X_train.to_numpy()).flatten()\n",
    "    pred_class = np.where(preds>0.5, 1, 0).flatten()\n",
    "    orig_acc = accuracy_score(y_train, pred_class)\n",
    "    orig_accs.append(orig_acc)\n",
    "    print(f\"Accuracy: {orig_acc:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_new_accs = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    new_accs = []\n",
    "    for col in cols_to_shuffle:\n",
    "        dummy = X_train.copy()\n",
    "        # Do this each time to ensure the old changes aren't permuted across\n",
    "        dummy[col] = np.random.permutation(X_train[col])\n",
    "\n",
    "        try:\n",
    "            preds = model.predict_proba(dummy.to_numpy())[:,1]\n",
    "        except:\n",
    "            preds = model.predict(dummy.to_numpy()).flatten()\n",
    "\n",
    "        pred_class = np.where(preds>0.5, 1, 0).flatten()\n",
    "        new_acc = accuracy_score(y_train, pred_class)\n",
    "        new_accs.append(new_acc)\n",
    "    all_new_accs.append(new_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame({'Feature': cols_to_shuffle})\n",
    "for i, accs in enumerate(all_new_accs):\n",
    "    change_in_acc = orig_accs[i] - np.array(accs)\n",
    "    # The importance of the feauture is proportional to the change in accuracy \n",
    "    importance = change_in_acc * (1/np.max(change_in_acc))\n",
    "    importance /= np.sum(importance)\n",
    "    a[list(models.keys())[i]] = importance\n",
    "\n",
    "a = a.sort_values('OLDNN', ascending=False)\n",
    "a.to_csv('permutation_importance.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "41e220d95b7ec8b8d5afec9fc37dd8786ce41c9f6ed7d4ccf5e0049ff2f60044"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('scientific')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
